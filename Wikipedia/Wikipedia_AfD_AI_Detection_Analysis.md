# Wikipedia AI Governance: The AfD Discussion Analysis
## How Editors Actually Detect and Delete AI-Generated Content

**Analysis Date**: November 4, 2025
**Sample**: 30 Articles for Deletion (AfD) discussions mentioning AI
**Total AfD pool**: 100 discussions found with AI mentions
**Data Source**: Wikipedia AfD namespace, 2023-2025

---

## Executive Summary

### **Major Finding: AI Governance Happens in Deletion Discussions, Not Policy Pages**

While Wikipedia has:
- **NO formal AI policy** (still draft proposal)
- **NO AI policy shortcut** (WP:NOTAI doesn't exist)
- **0 AI policy citations** in 10,000 edit summaries

Wikipedia editors are:
- **Actively detecting** AI-generated articles (100+ AfD discussions)
- **Successfully deleting** them (59% deletion rate)
- **Using detection tools** (GPTZero in 20% of cases)
- **Developing detection language** ("AI slop", "hallucination", "word salad")

**Conclusion**: Real AI governance is **bottom-up** (community practice) rather than **top-down** (formal policy).

---

## Detection Patterns

### 1. How Editors Identify AI-Generated Content

**Top Detection Indicators** (frequency in 30 discussions):

| Indicator | Mentions | Context |
|-----------|----------|---------|
| **GPT** | 170 | Generic reference to GPT technology |
| **ChatGPT** | 155 | Specific tool mention |
| **AI-generated** | 67 | Direct identification |
| **language model** | 35 | Technical term |
| **LLM** | 20 | Abbreviation for Large Language Model |
| **hallucination** | 3 | AI error/fabrication |
| **AI slop** | 2 | Derogatory term for low-quality AI content |
| **word salad** | 1 | Incoherent text pattern |

**Key Insight**: Editors primarily use **tool names** (ChatGPT, GPT) rather than symptom descriptions (hallucination, word salad).

---

### 2. Detection Tools Used

**GPTZero**: Mentioned in **6 out of 30 discussions (20%)**

**Sample Usage**:
> "Note: The above reply is 100% AI generated as per GPTZero."
> â€” AfD: International Jat Parliament

**Interpretation**:
- Only 20% of editors use formal detection tools
- Most detection is based on **human judgment** (style, errors, context)
- GPTZero is the only tool mentioned by name

**Question for further research**:
- What is the false positive rate?
- Do editors trust GPTZero results alone?
- Are there other tools used but not mentioned?

---

### 3. Language of Detection

Editors have developed **informal vocabulary** for AI content:

#### **Derogatory Terms**:
- **"AI slop"** (2 mentions) - Low-quality automated content
- **"AI-generated mess"** (multiple) - Disorganized content
- **"AI-generated garbage"** (multiple) - Worthless content
- **"word salad"** (1 mention) - Incoherent text

#### **Technical Terms**:
- **"hallucinate"** (3 mentions) - Generate false information
- **"hallucinated references"** - Fabricated citations
- **"machine-generated"** - Automated content
- **"bot-written"** - Automated authorship

#### **Neutral Terms**:
- **"AI-generated"** (67 mentions) - Factual description
- **"ChatGPT"** (155 mentions) - Tool attribution

**Insight**: The community is split between **neutral** ("AI-generated") and **pejorative** ("AI slop") framing.

---

## Deletion Outcomes

### Discussion Results (30 cases analyzed)

| Outcome | Count | Percentage |
|---------|-------|------------|
| **Delete** | 16 | 59% |
| **Keep** | 3 | 11% |
| **Withdrawn** | 1 | 4% |
| **Speedy delete** | 1 | 4% |
| **Redirect/Merge** | 2 | 7% |
| **Other/Unclear** | 5 | 19% |

**Key Findings**:
- **59% deletion rate** - AI-generated articles are usually deleted
- **11% keep rate** - Some AI content is salvageable
- **4% withdrawn** - Nominators sometimes change their mind

### Sample Deletion Reasons:

1. **"Chadian Refugees" AfD**:
 > "It is better to remove AI generated content and articles due to their tendency to hallucinate information and references, rather than waste volunteer time trying to clean them up."

2. **"Close-knit community" AfD**:
 > "Undisclosed, unsourced AI slop that would be just a WP:DICTDEF with examples anyway."

3. **"Artificial intelligence in education" AfD**:
 > "AI-generated slop with citations retroactively added but not necessarily supporting the text."

**Common Theme**: Editors emphasize AI's tendency to **fabricate information** and the **wastefulness** of cleanup efforts.

---

## Policy Citations in AfD Discussions

### Most Cited Policies (in AI-related AfD discussions):

| Policy | Citations | Meaning | AI Relevance |
|--------|-----------|---------|--------------|
| **WP:TNT** | 8 | Template No Thanks / Total Nuke & Rewrite | Article beyond repair |
| **WP:SIGCOV** | 4 | Significant Coverage | Lacks reliable sources |
| **WP:V** | 3 | Verifiability | Cannot verify claims |
| **WP:OR** | 2 | No Original Research | Unsourced assertions |
| **WP:RS** | 2 | Reliable Sources | Poor source quality |
| **WP:GNG** | 2 | General Notability Guideline | Subject not notable |

**Critical Insight**:
- **NO AI-SPECIFIC POLICIES CITED** (consistent with earlier findings)
- **WP:TNT most common** (8 citations) - suggests AI articles often "beyond repair"
- **Content quality policies** (V, RS, OR) applied to AI content
- Editors use **existing policies** to handle AI content

---

## Arguments in Deletion Discussions

### Delete Arguments (Top 10 AI-related):

1. **Hallucination concern**:
 > "Better to remove AI generated content... due to their tendency to hallucinate information and references, rather than waste volunteer time."

2. **No sources + AI**:
 > "Unreferenced, AI-generated mess."

3. **Dictionary definition**:
 > "Glorified WP:DICTDEF but with AI generated text. Even worse, it has no sources."

4. **Deception concern**:
 > "Undisclosed, unsourced AI slop... anyone trying to sneak this type of content onto WP should be blocked."

5. **Mass creation**:
 > "Creator was blocked for mass-creating AI-generated content, (also turned out to be a sock)."

6. **Quality degradation**:
 > "There's no way this AI-generated garbage can form the basis of a useful article."

7. **Obvious indicators**:
 > "From the user talk page it is obvious this person communicates only via AI texts."

8. **Citation fraud**:
 > "AI-generated slop with citations retroactively added but not necessarily supporting the text."

9. **Pattern recognition**:
 > "I've seen 5 AI-generated article related AFDs in the past month alone... Honestly kind of scary."

10. **Efficiency argument**:
 > "Even if this could theoretically be cleaned up, it's not worth the effort."

**Common Themes**:
- **Fabricated references** (hallucination)
- **Lack of sources** (verifiability)
- **Poor quality** (not salvageable)
- **Deception** (undisclosed AI use)
- **Time waste** (not worth cleaning)

---

### Keep Arguments (when AI is mentioned):

1. **Notable subject (Aristophilides)**:
 > "Keep and clean up any AI problems - he's obviously notable. Herodotus wrote of him as being the king of Taras."

2. **Valuable information (ChatGPT article)**:
 > "The ChatGPT Wikipedia article serves as a comprehensive and accessible resource... provides valuable information."

3. **Significant topic**:
 > "Should not be deleted... provides valuable information about an important language model."

**Common Theme**:
- **Notable subjects** can be kept despite AI-generation
- **Cleanup is possible** if subject merits it
- **Content value** outweighs generation method

**Critical Difference**:
- Delete arguments focus on **method** (AI-generated = bad)
- Keep arguments focus on **subject** (notable topic = worth saving)

---

## Case Studies

### Case 1: "Close-knit community" (Deleted)

**Why flagged as AI**:
- No sources
- Generic dictionary definition
- "Sounds like AI"

**Outcome**: Deleted

**Arguments**:
- "Glorified WP:DICTDEF but with AI generated text"
- "Undisclosed, unsourced AI slop"
- Multiple editors agreed

**Lesson**: AI + no sources + generic = almost certain deletion

---

### Case 2: "Sophia Dashing" (Withdrawn)

**Why flagged as AI**:
- "AI-generated slop"
- Lack of significant coverage

**Outcome**: **Withdrawn** by nominator

**Resolution**:
> "AI concerns have been addressed and another look shows WP:MUSICBIO criteria 1 is met."

**Lesson**: AI content can be **salvaged** if:
1. Someone fixes the AI problems
2. Subject meets notability criteria
3. Sources are added

**Insight**: Not all AI detection leads to deletion - cleanup is possible

---

### Case 3: "Malaccan-Siamese war" (User Blocked)

**Why flagged as AI**:
- "Hallucinated content and sources"
- Part of mass creation

**Outcome**: User blocked

**Escalation**:
> "For disrupting Wikipedia by creating AI-generated articles with hallucinated content and sources."

**Lesson**: Repeated AI article creation leads to **user blocks**, not just article deletion

**Implication**: Wikipedia treats systematic AI content creation as **disruptive behavior**

---

### Case 4: "International Jat Parliament" (Deleted)

**Why flagged as AI**:
- **GPTZero detection**: "100% AI generated as per GPTZero"
- User's talk page showed "communicates only via AI texts"

**Outcome**: Deleted

**Evidence**:
- Tool-based detection
- Pattern analysis (all user content AI-generated)

**Lesson**: **GPTZero validation** + **user behavior pattern** = strong case

---

### Case 5: "Aristophilides of Taras" (Kept)

**Why flagged as AI**:
- "Reads AI generated to me"

**Outcome**: **Kept**

**Counter-argument**:
> "Keep and clean up any AI problems - he's obviously notable. Herodotus wrote of him."

**Resolution**:
- Article cleaned up
- Notable subject (mentioned in JSTOR)
- AI problems fixable

**Lesson**: **Notability trumps generation method** if cleanup is feasible

---

## Enforcement Patterns

### 1. Detection Triggers

**What makes editors suspect AI**:

| Trigger | Examples |
|---------|----------|
| **No sources** | "Unreferenced, AI-generated mess" |
| **Generic content** | "Glorified dictionary definition" |
| **Writing style** | "Reads like AI", "sounds like AI" |
| **Hallucinated refs** | "Fabricated citations" |
| **User history** | "Communicates only via AI texts" |
| **Mass creation** | "5 AI articles in past month" |

**Most Reliable**: Combination of multiple triggers

---

### 2. Voting Patterns

**Average voters per discussion**: 2.8

**Interpretation**:
- AI AfD discussions are **relatively small** (compared to controversial topics)
- Suggests **quick consensus** on obvious AI content
- Community agreement on AI being problematic

---

### 3. Community Norms Emerging

**Implicit Rules** (not formal policy):

1. **Undisclosed AI use is unacceptable**
 - "Sneaking AI content" is seen as deceptive

2. **Hallucinated sources are serious violations**
 - Worse than no sources (creates false information)

3. **Mass AI creation warrants blocking**
 - Systematic abuse treated as disruption

4. **Notable subjects can be salvaged**
 - AI generation doesn't automatically doom article

5. **Cleanup effort must be justified**
 - Not worth fixing if subject isn't notable

**Insight**: Community is developing **informal AI policies** through practice, even without formal rules.

---

## Comparison: Policy vs. Practice

### What the Data Shows:

| Aspect | Formal Policy | Actual Practice |
|--------|---------------|-----------------|
| **AI policy exists?** | No (draft only) | Yes (informal norms) |
| **Enforcement mechanism** | None | AfD discussions |
| **Detection method** | Not specified | Human judgment + GPTZero |
| **Cited in edits** | 0 times in 10,000 edits | N/A |
| **Cited in AfD** | 0 times in 30 discussions | Uses WP:V, WP:RS instead |
| **Deletion rate** | N/A | 59% |
| **Tools mentioned** | None | GPTZero (20% of cases) |

**Critical Insight**:
- **Formal policy lags practice** by ~2+ years
- Community has **working governance** without formal rules
- **Existing policies** (WP:V, WP:RS) sufficient for AI cases

---

## Temporal Trends

### Observation from AfD Data:

One editor noted:
> "I've seen 5 AI-generated article related AFDs in the past month alone. Prior to that, I had not seen one. Honestly kind of scary if you ask me."

**Implication**:
- AI article creation is **increasing** (especially in 2025)
- Editors are **noticing the trend**
- Concern about **scale of problem**

**Cross-reference with earlier finding**:
- Our targeted analysis showed **63 AI edits in 2025** (vs 44 in 2023)
- Consistent with increased AI article creation

---

## Detection Accuracy

### GPTZero Usage (6 cases, 20% of sample):

**Confidence levels observed**:
- "100% AI generated as per GPTZero" (1 case)
- Other cases mention GPTZero but don't report confidence

**Questions**:
1. What is GPTZero's false positive rate?
2. Do editors verify GPTZero results?
3. Is GPTZero authoritative, or just supporting evidence?

**Observation**:
- Even with GPTZero, editors cite **other evidence** (no sources, writing style)
- Suggests **tool + human judgment** model

---

### Human Detection Patterns:

**Phrases used**:
- "reads like AI"
- "sounds like AI"
- "looks AI generated"
- "obviously AI"

**What editors look for** (implicit):
- Generic/formulaic writing
- Lack of specific details
- Perfect grammar but awkward phrasing
- Fabricated citations
- Dictionary-like definitions
- No sources

**Limitation**:
- Subjective judgments
- No clear detection criteria
- Risk of false positives

---

## Policy Gaps Identified

### What's Missing from Formal Wikipedia Policy:

1. **AI detection guidelines**
 - How to identify AI content
 - What tools to use
 - Confidence thresholds

2. **AI usage policy**
 - Is AI-assisted writing allowed?
 - Must AI use be disclosed?
 - What level of AI use is acceptable?

3. **Enforcement procedures**
 - When to delete vs. cleanup
 - User warning/blocking criteria
 - Appeal process

4. **Quality standards**
 - Is well-sourced AI content acceptable?
 - Does generation method matter if result is good?

5. **Edge cases**
 - AI translation
 - AI-assisted research
 - AI citation formatting

**Current State**: All handled **ad hoc** in individual AfD discussions

---

## Implications for Your Research

### Wikipedia's AI Governance Model:

**Characteristics**:
1. **Bottom-up** (community practice, not top-down policy)
2. **Distributed** (individual editors detect and flag)
3. **Deliberative** (AfD discussions build consensus)
4. **Tool-assisted** (GPTZero used by ~20%)
5. **Norm-based** (informal rules emerging)
6. **Existing-policy-adapted** (WP:V, WP:RS applied to AI)

**Strengths**:
- Flexible and adaptive
- Community-driven consensus
- Works without formal policy
- Quick response to new problems

**Weaknesses**:
- Inconsistent standards
- Subjective detection
- No clear guidelines for edge cases
- Risk of false positives
- Difficult to scale

---

### Comparison Framework for Software Projects:

**Questions to ask about Apache/FSF**:

1. **Detection**:
 - How do they detect AI-generated code?
 - What tools do they use?
 - Is detection easier/harder than text?

2. **Policy**:
 - Do they have formal AI policies?
 - Are policies cited in discussions?
 - Top-down vs. bottom-up?

3. **Enforcement**:
 - What happens to AI-generated PRs?
 - Are users warned/banned?
 - Deletion rate?

4. **Language**:
 - What terms do they use?
 - Pejorative vs. neutral?
 - Similar to Wikipedia?

5. **Philosophy**:
 - Open-source (pragmatic) vs. free-software (ideological)?
 - Does generation method matter?
 - Focus on quality or provenance?

---

## Key Takeaways

### 1. **"Invisible" Formal Policy, Visible Informal Governance**

- Wikipedia has NO formal AI policy
- But has ACTIVE AI governance through AfD discussions
- Community practice precedes policy formalization

### 2. **Detection is Human-Centered**

- Only 20% use detection tools (GPTZero)
- Most rely on "reads like AI" judgment
- Subjective but seemingly effective (59% deletion rate)

### 3. **Language Reveals Attitudes**

- "AI slop" (pejorative) vs. "AI-generated" (neutral)
- Focus on **hallucination** and **fabrication**
- Emphasis on **wasted cleanup effort**

### 4. **Existing Policies Applied to AI**

- No AI-specific policy citations
- WP:TNT, WP:V, WP:RS used instead
- Governance framework adapts to new challenges

### 5. **Notability Trumps Method**

- AI-generated articles on notable subjects can be kept
- Generation method matters less than content quality
- Cleanup is acceptable if subject merits it

### 6. **Scale is Increasing**

- Editors noting more AI articles in 2025
- Concern about systematic abuse
- May force formal policy creation

---

## Next Steps for Research

### For Wikipedia:

1. **Monitor policy development**
 - Will Wikipedia:AI-generated content be adopted?
 - What compromises will be made?
 - Timeline for formal policy?

2. **Track enforcement trends**
 - Are AfD cases increasing?
 - Is detection improving?
 - Are false positives occurring?

3. **Study successful cleanups**
 - Which AI articles were salvaged?
 - What made cleanup feasible?
 - Best practices emerging?

### For Software Project Comparison:

1. **Analyze Apache Foundation**
 - GitHub PR discussions
 - Mailing list archives
 - Commit message patterns
 - Policy documents

2. **Analyze FSF/GNU**
 - Savannah discussions
 - Mailing lists
 - Policy statements
 - Philosophical writings

3. **Compare governance models**
 - Wikipedia: Bottom-up, AfD-based
 - Apache: TBD
 - FSF: TBD
 - Open-source vs. free-software differences?

---

## Data Summary

```
Analysis Date: November 4, 2025
Sample: 30 AfD discussions (100 total pool)
Time Period: 2023-2025

Detection Indicators: 80 total
 - GPT: 170 mentions
 - ChatGPT: 155 mentions
 - AI-generated: 67 mentions

Detection Tools: GPTZero (6 cases, 20%)

Outcomes:
 - Delete: 16 (59%)
 - Keep: 3 (11%)
 - Other: 11 (30%)

Policies Cited: 51 total
 - WP:TNT: 8
 - WP:SIGCOV: 4
 - WP:V: 3
 - NO AI-specific policies

Average voters: 2.8 per discussion
Total voters analyzed: 85

Key Terms:
 - "AI slop" (2)
 - "hallucination" (3)
 - "word salad" (1)
```

---

**Conclusion**: Wikipedia's AI governance is a **case study in emergent policy** - the community has developed working detection, discussion, and deletion processes **without formal policy**, through distributed practice and norm-building in AfD discussions. This bottom-up model may inform how software projects can (or cannot) govern AI-generated contributions.

---

**Data Files**:
- `wikipedia_afd_ai_patterns_20251104_180544.json`
- `wikipedia_ai_talk_discussions_20251104_180104.json`
- `wikipedia_policy_citations_2025_20251104_175208.json`

**Analysis Tools**:
- `wikipedia_afd_ai_pattern_analyzer.py`
- `wikipedia_ai_talk_discussion_analyzer.py`
- `wikipedia_policy_citation_analyzer.py`
