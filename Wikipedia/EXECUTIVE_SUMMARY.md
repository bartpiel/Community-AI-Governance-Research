# Wikipedia AI Governance Research - Executive Summary

**Research Period**: October 30 - November 4, 2025
**Research Question**: How does Wikipedia govern AI-generated content in the absence of formal AI-specific policies?

---

## üéØ Main Findings

### **1. The "Invisible Policy" Paradox**

Wikipedia has **NO formal AI policy** yet maintains **active AI governance**:

- ‚ùå No adopted AI policy (Wikipedia:AI-generated content is still a **draft proposal**)
- ‚ùå No AI policy shortcuts exist (WP:NOTAI doesn't exist)
- ‚ùå **0 AI policy citations** found in 10,000 recent edits (0.000%)
- ‚úÖ **100+ active deletion discussions** about AI-generated articles
- ‚úÖ **59% deletion rate** for AI-generated content
- ‚úÖ **Bottom-up governance** through community practice

**Conclusion**: AI governance happens through **emergent community norms**, not top-down policy.

---

### **2. Detection Methods**

**How editors identify AI-generated content:**

| Method | Usage | Reliability |
|--------|-------|-------------|
| **Human judgment** | 80% | "Reads like AI", style-based |
| **GPTZero tool** | 20% | Explicit detection tool |
| **Pattern recognition** | Common | Hallucinated refs, no sources, generic text |
| **User history** | Occasional | "Communicates only via AI texts" |

**Top Detection Indicators** (in 30 AfD discussions):
- GPT: 170 mentions
- ChatGPT: 155 mentions
- AI-generated: 67 mentions
- Language model: 35 mentions
- Hallucination: 3 mentions

---

### **3. Community Language**

Editors developed informal vocabulary:

**Pejorative Terms**:
- "AI slop" (2 mentions) - Low-quality content
- "AI garbage/mess" - Worthless content
- "Word salad" (1 mention) - Incoherent text

**Technical Terms**:
- "Hallucination" (3 mentions) - Fabricated information
- "Hallucinated references" - Fake citations

**Key Insight**: Language reveals negative attitude toward AI-generated content, with emphasis on **deception** (undisclosed AI use) and **wasted effort** (cleanup time).

---

### **4. Enforcement Mechanisms**

**Where AI governance happens:**

1. **Articles for Deletion (AfD)**: 100+ discussions
   - 59% deletion rate
   - Consensus-based decisions
   - 2.8 average voters per discussion

2. **WikiProject AI Cleanup**: 207 watchers
   - Monitors AI-topic articles
   - Coordinates detection efforts
   - No separate AI policies (uses Wikipedia-wide rules)

3. **Village Pump (Policy)**: 50+ discussions
   - Policy proposals debated
   - Draft AI policy under development

4. **User blocks**: Systematic AI article creation ‚Üí blocking
   - "Disrupting Wikipedia by creating AI-generated articles with hallucinated content"

---

### **5. Deletion Arguments**

**Most common reasons for deleting AI-generated articles:**

1. **Hallucinated references** (fabricated citations)
2. **Lack of sources** (unverifiable claims)
3. **Wasted cleanup effort** ("not worth volunteer time")
4. **Undisclosed AI use** (deception)
5. **Mass creation** (systematic abuse)

**Key Argument**:
> "It is better to remove AI generated content... due to their tendency to hallucinate information and references, rather than waste volunteer time trying to clean them up."

---

### **6. When AI Content Survives**

**3 cases (11%) resulted in "Keep" decisions:**

**Criteria for keeping AI-generated content:**
- ‚úÖ **Notable subject** (e.g., historical figure mentioned by Herodotus)
- ‚úÖ **Cleanup feasible** (problems can be fixed)
- ‚úÖ **Sources added** (verifiability established)
- ‚úÖ **Content valuable** (despite generation method)

**Key Principle**: **Notability trumps method** - generation method matters less than content quality.

---

### **7. Policy Application**

**Most cited policies in AI AfD discussions:**

| Policy | Citations | Meaning | AI Relevance |
|--------|-----------|---------|--------------|
| WP:TNT | 8 | Total Nuke & Rewrite | Article beyond repair |
| WP:SIGCOV | 4 | Significant Coverage | Lacks sources |
| WP:V | 3 | Verifiability | Can't verify claims |
| WP:OR | 2 | No Original Research | Unsourced assertions |

**Critical Finding**: **NO AI-specific policies cited** - existing content quality policies applied to AI cases.

---

### **8. Temporal Trends**

**AI content is increasing:**

- **2023**: 44 AI-related edits
- **2024**: 9 AI-related edits
- **2025**: 63 AI-related edits (to Nov 4)

**Editor observation**:
> "I've seen 5 AI-generated article AFDs in the past month alone. Prior to that, I had not seen one. Honestly kind of scary if you ask me."

**Implication**: Growing scale may force formal policy adoption.

---

### **9. Centralized vs. Decentralized Governance**

**WikiProject Analysis** (1,096+ projects examined):

- ‚ùå **0 WikiProjects** have separate AI policies
- ‚úÖ All use **centralized Wikipedia policies**
- ‚úÖ WikiProject AI Cleanup acts as **coordinating hub**, not autonomous policy-maker

**Governance Model**: **Centralized policy + distributed enforcement**

---

### **10. Policy vs. Practice Gap**

**Comparison of formal vs. actual governance:**

| Aspect | Formal Policy | Actual Practice |
|--------|---------------|-----------------|
| **AI policy exists** | No (draft only) | Yes (informal norms) |
| **Policy citations** | 0 in 10,000 edits | Uses WP:V, WP:RS instead |
| **Detection tools** | Not specified | GPTZero (20% usage) |
| **Deletion mechanism** | Not defined | AfD discussions |
| **Deletion rate** | N/A | 59% |
| **User consequences** | Not defined | Blocking for mass creation |

---

## üìä Key Statistics

### Policy Citation Analysis (10,000 edits, 2025)
```
Total policy citations:          1,820
‚îú‚îÄ AI-specific policies:             0  (0.000%)
‚îú‚îÄ Bot/automation policies:        311  (17.1%)
‚îî‚îÄ Other policies:               1,509  (82.9%)

Most cited: WIKIPEDIA:CATEGORIES (638, 35%)
AI shortcuts: WP:AI ‚Üí Info page (not policy)
              WP:NOTAI ‚Üí Does NOT exist
```

### AfD Discussion Analysis (30 discussions, 2023-2025)
```
Total discussions found:         100
Analyzed in depth:                30
Detection indicators:             80

Outcomes:
‚îú‚îÄ Delete:                    16 (59%)
‚îú‚îÄ Keep:                       3 (11%)
‚îî‚îÄ Other:                     11 (30%)

Detection tools:
‚îî‚îÄ GPTZero:                6 cases (20%)

Policies cited:              51 total
‚îî‚îÄ NO AI-specific policies cited
```

### WikiProject Analysis (1,096+ projects)
```
Total WikiProjects found:      1,096+
Analyzed in depth:                 50

Top WikiProject: AI Cleanup
‚îú‚îÄ Watchers:                      207
‚îú‚îÄ AI references:                 109
‚îî‚îÄ Separate AI policy:             NO

WikiProjects with AI policies:      0
```

---

## üîë Research Implications

### **1. Bottom-Up Governance Model**

Wikipedia demonstrates that **effective AI governance can emerge without formal policy**:

- ‚úÖ Community develops detection practices
- ‚úÖ Norms emerge through deletion discussions
- ‚úÖ Existing policies adapted to new challenges
- ‚úÖ Distributed enforcement works

**Challenge**: Inconsistent standards, subjective detection

---

### **2. Detection Challenges**

**Current state of AI detection:**

- Most detection is **subjective** ("reads like AI")
- Only 20% use **formal tools** (GPTZero)
- Detection based on **secondary indicators** (no sources, generic content)
- **False positive risk** (no systematic validation)

**Need**: Better detection tools, clearer criteria

---

### **3. Hallucination as Critical Issue**

**Fabricated citations are treated as serious violations:**

- Worse than no sources (creates false information)
- Primary argument for deletion
- May warrant user blocking

**Insight**: AI's hallucination problem drives governance responses

---

### **4. Efficiency Argument**

**Community prioritizes volunteer time:**

- "Not worth cleaning up" is valid deletion argument
- Even salvageable content may be deleted if cleanup is expensive
- Threshold question: Is subject notable enough to justify effort?

**Principle**: **Return on investment** matters in volunteer-driven governance

---

### **5. Formal Policy Lag**

**Timeline of AI governance development:**

- **2023**: AI content starts appearing
- **2023-2024**: Community develops informal norms
- **2024-2025**: Increased AI article creation
- **2025**: Draft policy still under development
- **Future**: Formal policy adoption?

**Pattern**: **Practice precedes policy** by 2+ years

---

## üéì Comparative Framework

### **For Comparing with Software Projects (Apache, FSF):**

**Questions to investigate:**

1. **Detection**:
   - Is AI-generated code easier/harder to detect than text?
   - What tools exist for code detection?
   - Pattern recognition in commits?

2. **Policy**:
   - Do software projects have formal AI policies?
   - Are policies cited in discussions?
   - Top-down vs. bottom-up governance?

3. **Philosophy**:
   - Open-source (pragmatic) vs. free-software (ideological)?
   - Does generation method matter or only quality?
   - Licensing implications?

4. **Enforcement**:
   - What happens to AI-generated PRs?
   - Code review processes?
   - Contributor consequences?

5. **Language**:
   - Similar vocabulary ("AI slop")?
   - Attitude toward AI assistance?
   - Distinction between AI-assisted vs. AI-generated?

---

## üî¨ Methodology

### **Data Collection**

**1. Policy Analysis**:
- Wikipedia Action API (query, parse, search endpoints)
- Analyzed 42 policy pages with 581 AI references
- Time period: Full Wikipedia history

**2. WikiProject Analysis**:
- Fetched 1,096+ WikiProjects via API
- Analyzed top 50 by popularity
- Searched for AI-specific policies (found 0)

**3. Edit History Analysis**:
- Random sample: 30 articles (FAILED - 0% hit rate)
- Targeted sample: 13 articles from WikiProject AI Cleanup (SUCCESS - 46% hit rate)
- Found 116 AI-related edits

**4. Policy Citation Analysis**:
- Analyzed 10,000 recent edits (2025)
- Extracted 1,820 policy citations
- Found 0 AI-specific policy citations

**5. Talk Discussion Analysis**:
- Searched 118 discussion spaces
- 50 Village Pump discussions
- 42 AfD discussions
- 22 WikiProject sections

**6. AfD Deep Dive**:
- Analyzed 30 deletion discussions in depth
- Extracted 80 detection indicators
- Catalogued arguments and outcomes

---

## üìÅ Repository Contents

### **Analysis Reports**:
1. `Complete_Wikipedia_AI_Governance_Analysis.md` - Initial comprehensive analysis
2. `Wikipedia_WikiProject_AI_Policy_Analysis.md` - WikiProject governance structure
3. `AI_Enforcement_Preliminary_Analysis.md` - Random sampling (negative result)
4. `AI_Enforcement_Targeted_Analysis.md` - Targeted enforcement analysis
5. `Wikipedia_AI_Policy_Citation_Analysis_2025.md` - Policy usage quantification
6. `Wikipedia_AfD_AI_Detection_Analysis.md` - Deletion discussion deep dive

### **Python Scripts**:
- `wikipedia_ai_governance_analyzer.py` - General AI governance analysis
- `wikipedia_wikiproject_ai_analyzer.py` - WikiProject enumeration and analysis
- `wikipedia_ai_enforcement_analyzer.py` - Random edit sampling
- `wikipedia_ai_enforcement_targeted_analyzer.py` - Targeted enforcement analysis
- `wikipedia_policy_citation_analyzer.py` - Policy citation frequency
- `wikipedia_ai_talk_discussion_analyzer.py` - Discussion space search
- `wikipedia_afd_ai_pattern_analyzer.py` - AfD deep analysis

### **Data Files** (CSV/JSON):
- Policy analysis data
- WikiProject data (1,096+ projects)
- Edit enforcement data (116 AI edits)
- Policy citation data (1,820 citations)
- AfD discussion data (100+ discussions)

---

## üí° Key Insights

### **1. Governance Without Policy Works (But Has Limits)**

Wikipedia shows that **informal community norms can effectively govern AI content**, but:
- Inconsistent standards
- Subjective detection
- Difficult to scale
- Eventually needs formalization

---

### **2. Existing Frameworks Adapt**

Rather than creating new AI-specific policies, Wikipedia **applies existing policies**:
- WP:V (Verifiability) ‚Üí AI content often unverifiable
- WP:RS (Reliable Sources) ‚Üí AI fabricates citations
- WP:OR (Original Research) ‚Üí AI generates unsourced claims

**Lesson**: New technology doesn't always need new rules.

---

### **3. Detection is the Bottleneck**

**Biggest challenge**: Reliably identifying AI-generated content
- Human judgment is subjective
- Detection tools (GPTZero) only used in 20% of cases
- Risk of false positives/negatives

**Implication**: Governance effectiveness limited by detection capability

---

### **4. Community Trust Matters**

**Key concerns driving deletion**:
- Undisclosed AI use (deception)
- Hallucinated references (false information)
- Mass creation (systematic abuse)

**Pattern**: Breach of trust more important than technical quality issues

---

### **5. Pragmatism Wins**

Despite concerns about AI, Wikipedia keeps AI-generated content when:
- Subject is notable
- Sources are added
- Content is valuable
- Cleanup is feasible

**Philosophy**: **Results matter more than provenance** (if quality standards are met)

---

## üöÄ Future Research Directions

### **For Wikipedia**:
1. Monitor formal policy adoption process
2. Track detection accuracy (false positives/negatives)
3. Study successful cleanup cases
4. Analyze temporal trends (is AI content increasing?)

### **For Software Projects**:
1. Apache Foundation AI governance analysis
2. FSF/GNU philosophical stance on AI
3. Compare open-source vs. free-software approaches
4. Code vs. content governance differences

### **Cross-Domain**:
1. Community-driven vs. foundation-driven governance
2. Content vs. code detection challenges
3. Legal/licensing implications
4. Philosophical differences (pragmatic vs. ideological)

---

## üìö Citation

**Repository**: Apache-Foundation-Projects/Wikipedia
**Research Period**: October 30 - November 4, 2025
**Data Sources**: Wikipedia API, AfD discussions, WikiProject pages, edit histories
**Methodology**: Mixed methods (quantitative API analysis + qualitative discussion analysis)

---

## ü§ù Acknowledgments

**Data Source**: Wikipedia community (editors, administrators, WikiProjects)
**API**: Wikimedia Action API
**Tools**: Python 3, requests library, Wikipedia API endpoints

---

## üìñ Further Reading

**Wikipedia Policy Pages**:
- Wikipedia:AI-generated content (draft proposal)
- Wikipedia:Verifiability
- Wikipedia:Reliable sources
- Wikipedia:No original research

**WikiProjects**:
- Wikipedia:WikiProject AI Cleanup (207 watchers)
- Wikipedia:WikiProject AI Cleanup/Guide
- Wikipedia:WikiProject AI Cleanup/Policies

**Community Discussions**:
- Wikipedia:Village pump (policy) - AI discussions
- Wikipedia:Articles for deletion - AI-generated articles
- Wikipedia talk:AI-generated content

---

**Last Updated**: November 4, 2025
**Status**: Analysis complete, ready for comparison with software projects
