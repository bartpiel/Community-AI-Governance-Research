article,section_title,matching_phrases,policies_cited,excerpt,section_length
ChatGPT,Introduction,ChatGPT,None,{{pp-protected|small=yes}} {{Talk header}} {{Notice|1=This [[WP:TALK|talk page]] is semi-protected due to an unmanageable torrent of edits from people who think this is where you may ask ChatGPT a question. It is not. If you cannot edit this page and want to request an edit that is about '''improvin,1528
Generative pre-trained transformer,GPT as a generic term,"GPT-3, language model",None,"FWIW, I asked GPT-3.5 the following question and was answered as follows:   ""Do you think GPT is a generic term for a kind of AI?   Yes, 'GPT' (Generative Pre-trained Transformer) is a specific type of language model developed by OpenAI, but the term is often used as a general descriptor for a type",2746
Generative pre-trained transformer,Focus of this article,"ChatGPT, language model",None,"I think we need to have a good discussion about what this article should look like because there are some pretty big problems with it now, and it's starting to [https://pageviews.wmcloud.org/?project=en.wikipedia.org&platform=all-access&agent=user&redirects=0&range=latest-30&pages=Generative_pre-tr",11654
Generative pre-trained transformer,Article expansion (adding of background),"GPT-3, language model",None,"hey, few weeks ago we had a conversation about huge Background section in the GPT-2 article. I believe it belongs here, not there. Please see [[Talk:GPT-2#Background_section]]. Also pinging {{u|JPxG}}. [[User:Artem.G|Artem.G]] ([[User talk:Artem.G|talk]]) 16:15, 12 April 2023 (UTC)  :I agree that m",5286
Generative pre-trained transformer,Merge with [Chat?]GPT,"ChatGPT, language model",None,"Proposal to merge with [[Generative Pre-trained Transformer]]  OpenAI has filed a trademark for GPT. There will prbably be no contenders, as they have invented the term. [https://tmsearch.uspto.gov/bin/showfield?f=doc&state=4803:7343mt.2.16]   GPT is more akin to a commercial name, rather than a ge",5377
Generative pre-trained transformer,Summary of proposal from the previous section,ChatGPT,None,"::TL;DR Very small page, criticized as without clear focus, probably because it's hard to distinguish from [[ChatGPT]]. Merge to ChatGPT if there's any data then delete.--[[User:TZubiri|TZubiri]] ([[User talk:TZubiri|talk]]) 03:27, 25 April 2023 (UTC) :::I doubt that proposal would gain much suppo",880
Generative pre-trained transformer,Training cost of GPT-n series,"GPT-3, GPT-4, language model",None,"GPT-1: There is absolutely no information about what they meant by ""1 month on 8 GPUs"". I suspect it's V100 GPU, but it has 100 TFLOP/sec, which would give 2e21 FLOP, which is way too high.  GPT-2: The only mention from official source is ""tens of petaflop/s-day"", so about 1e21 FLOP...   GPT-3: The",2212
Generative pre-trained transformer,Large language models,language model,None,"Are all GPTs large language models, as implied by the lead sentence? Surely a smaller language model could also be trained as a GPT, right? –<span style=""box-shadow: 0px 0px 12px red;border-radius:9em;padding:0 2px;background:#D00"">[[User:Gluonz|<span style=""color:#AFF"">'''Gluonz'''</span>]]<sup>''",1117
Generative pre-trained transformer,Generative Pre-Trained Transformer architecture vs models,language model,None,"Current page does not distinguish between the architecture and the models itself. GPT architecture could be used to train any model, not just language models like the article implies. OpenAI have been using the GPT acronym for its large language models but this is not sole thing it can be used for.",904
Hallucination (artificial intelligence),Some Examples of Hallucination are better than others.,ChatGPT,None,"The article currently states: <code>Mike Pearl of Mashable tested ChatGPT with multiple questions. In one example, he asked the model for ""the largest country in Central America that isn't Mexico"". ChatGPT responded with Guatemala, when the answer is instead Nicaragua.</code> While this does at fir",1336
Hallucination (artificial intelligence),Hallucinating non-existent APIs,ChatGPT,WP:RS,A German geocoding company was flooded by dissatisfied customers trying to use code ChatGPT wrote: https://the-decoder.com/company-wins-customers-via-chatgpt-for-a-product-it-does-not-carry And [[EleutherAI]] complained people keep trying to access a URL they don't have on their website: https://tw,835
Hallucination (artificial intelligence),Does this event belong on this page?,ChatGPT,None,"https://www.theguardian.com/technology/2025/aug/12/us-man-bromism-salt-diet-chatgpt-openai-health-information  https://thehill.com/policy/technology/5446903-sodium-bromide-poisoning-chatgpt-advice/ [[User:Cahlin29|Cahlin29]] ([[User talk:Cahlin29|talk]]) 07:42, 13 August 2025 (UTC)",285
Hallucination (artificial intelligence),"Is this really ""low"" importance?",ChatGPT,None,"AI ""hallucinations"" are a serious problem for everyday people who tend to believe the first thing that LLMs spit out. I've repeatedly experienced errors from every AI from ChatGPT and more esp. Grok. I've even got into verbal altercations with both of them.  Microsoft's ChatGPT extensions also give",1620
Prompt engineering,Restrictions of a Context Window,"AI-generated, language model",None,Context Window and Token cap  in every request (reasoning and must be mentioned in the article of Prompt engineering).   The [[Context window|Context Window]] (or simply [[Context length|Context Length]]) is a principal limitation on information an [[Large language model|LLM]] can process and/or pro,2515
Prompt engineering,Prompt Examples,ChatGPT,"WP:RS, WP:NOR",I submitted a prompt asking for a variety of prompt suggestions shown below to ChatGPT (Mar 14 Version. Free Research Preview) shortly before posting here. I also included the text of the main article. Shown below are a few prompt examples suggested by ChatGPT.  I wanted to post the results to the,2904
Prompt engineering,Using feedback from ChatGPT (3.5) I finalized my work on the lede,"ChatGPT, language model",None,"I have kept rewriting (rephrasing) the lede until I got tired. I then decided to ask for help the ChatGPT (3.5, the free version), using the technique of prompt engineering itself. Using feedback from it, I crafted the lede as of [https://en.wikipedia.org/w/index.php?title=Prompt_engineering&oldid=",3326
Prompt engineering,Edit for [[WP:INTEGRITY]],"GPT-4, language model",None,"Comparing a previous revision [https://en.wikipedia.org/w/index.php?title=Prompt_engineering&oldid=1162303092] of this article with the current[https://en.wikipedia.org/w/index.php?title=Prompt_engineering&oldid=1170312478] version, I noticed several issues:  * [[WP:DEADREF]] - At least 11 other pa",6252
Prompt engineering,Neutral point of view,"GPT-3, language model","WP:RS, WP:COI","This article seems, at least in its current form, to be highly biased towards the idea that ""prompt engineering"" is scientifically valid; that's far from the consensus understanding in computer science, however. Indeed, most of the citations on this page are either unpublished preprints, press rele",15475
Prompt engineering,Neutrality issue not resolved,"ChatGPT, GPT-3, GPT-4",WP:COI,"It looks like the NPOV template was removed, but none of the POV issues have been addressed. This page still seems to take the strong and non-consensus stance that, rather than being a pseudoscience, prompt engineering is an actual and valid avenue of scientific research. It is not, that view is a",6221
Villa Llao Llao,Introduction,AI-generated,None,{{WikiProject banner shell|class=Stub| {{WikiProject Argentina|topic=geo|importance=mid}} }} {{Press  |author      = Daniel Wu  |title       =  Volunteers fight to keep ‘AI slop’ off Wikipedia  |date        =  8 August 2025  |org         = [[The Washington Post]]  |url         = https://www.washingt,407
